
# ğŸ¤– Q&A Interview Assistant (LLM Fine-Tuning Project)

This project fine-tunes a GPT-2 language model for generating ideal answers to technical and behavioral interview questions so that freshly-graduated AI students can practice using it. 
---

## ğŸ“ Project Structure

- `Q&A_data.csv` - The dataset containing interview questions and ideal answers.
- `Training_chatbot.ipynb` - Notebook for formatting, tokenizing and fine-tuning GPT-2.
- `Evaluate.ipynb` - Script to evaluate model outputs using BLEU and ROUGE scores.
- `Chatbot.ipynb` - Deploying the chatbot.
- `requirements.txt` - List of dependencies.
- `interview_model` - Folder containing the fine-tuned model and tokenizer.

---

## âš™ï¸ Setup

### Step 1:
Install the requirements by using the following command

```bash
pip install -r requirements.txt
```
### Step 2: (Optional)
Train the model by running `Training_chatbot.ipynb`

### Step 3: (Optional)
Evaluate the mode4l by running `Evaluate.ipynb`

### Step 4:
Deploy the model by running `Chatbot.ipynb`

---


## ğŸ‘©â€ğŸ’» Contributors

This project was developed by senior AI students at Imam Abdulrahman Bin Faisal University (IAU):

- **Reem**
- **Jumanah**
- **Maryam**
- **Raghad**
- **Lama**

We welcome feedback and contributions. If you're interested in collaborating or have suggestions, feel free to open an issue or contact us via GitHub.

---
